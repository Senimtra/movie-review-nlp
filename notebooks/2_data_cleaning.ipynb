{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Step 1: Removing duplicates](#step-1-removing-duplicates)\n",
    "- [Step 2: One-Hot-encoding labels](#step-2-one-hot-encoding-labels)\n",
    "- [Step 3: Removing HTML, brackets & special characters](#step-3-removing-html-brackets--special-characters)\n",
    "- [Step 4: Handling contractions](#step-4-handling-contractions)\n",
    "- [Step 5: Applying spell check](#step-5-applying-spell-check)\n",
    "- [Step 6: Converting to lowercase](#step-6-converting-to-lowercase)\n",
    "- [Step 7: Train-Test split the data](#step-7-train-test-split-the-data)\n",
    "- [Step 8: Saving preprocessed data](#step-8-saving-preprocessed-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/imdb_train.csv')\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = data[data.duplicated()]\n",
    "\n",
    "print('Duplicates found:', len(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "print('Remaining reviews:', data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: One-Hot-encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Removing HTML, brackets & special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing HTML line-breaks + links\n",
    "\n",
    "def remove_html_links(review_text):\n",
    "    # Remove HTML line breaks <br />\n",
    "    text = re.sub(r'<.*?>', ' ', review_text)\n",
    "    # Remove http(s) links\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    # Remove dots between capital letters\n",
    "    text = re.sub(r'(?<=\\b[A-Z])\\.(?=[A-Z]\\b)', '', text)\n",
    "    # Remove parentheses with only numbers inside\n",
    "    text = re.sub(r'\\(\\d+\\)', '', text)\n",
    "    # Remove parentheses with content where all words are capitalized\n",
    "    text = re.sub(r'\\(([A-Z][a-z]*(?: [A-Z][a-z]*)*)\\)', '', text)\n",
    "    # Remove all dots between letters and '!' or '?'\n",
    "    text = re.sub(r'(?<=[a-zA-Z])\\.+(?=[!?])', '', text)\n",
    "    # Replace multiple '!', '?' or '-' with just one of each in sequence\n",
    "    text = re.sub(r'[!?-]+', lambda x: ''.join(sorted(set(x.group(0)), key=x.group(0).find)), text)\n",
    "    # Replace sequences of more than two identical letters with exactly two\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    # Replace '@' between letters with a space\n",
    "    text = re.sub(r'(?<=[a-zA-Z])@(?!\\s)', 'a', text)\n",
    "    # Replace '\\', '/' and '>' with a space\n",
    "    text = re.sub(r'[\\\\/>]', ' ', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Replace ' & ' with 'and'\n",
    "    cleaned_text = re.sub(r' \\& ', ' and ', text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "data['review'] = data['review'].apply(remove_html_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing brackets\n",
    "\n",
    "# def replace_brackets(text):\n",
    "#     text = re.sub(r'[\\[{]', '(', text)\n",
    "#     text = re.sub(r'[\\]}]', ')', text)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Handling contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "data['review'] = data['review'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5: Applying spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance = 2, prefix_length = 7)\n",
    "\n",
    "sym_spell.load_dictionary('../data/frequency_dictionary_en_82_765.txt', term_index = 0, count_index = 1)\n",
    "\n",
    "preserve = {'.', '?', '!', ',', '-', ':', ';', '(', ')'}\n",
    "\n",
    "skip_chars = {'I'}\n",
    "\n",
    "def spell_check(text):\n",
    "    # Splitting text into words and punctuation marks\n",
    "    tokens = re.findall(r'\\w+|\\S', text)\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalnum() and token not in preserve and token not in skip_chars:\n",
    "            suggestions = sym_spell.lookup(token, Verbosity.CLOSEST, max_edit_distance = 2)\n",
    "            corrected_token = suggestions[0].term if suggestions else token\n",
    "            corrected_tokens.append(corrected_token)\n",
    "        else:\n",
    "            corrected_tokens.append(token)\n",
    "    # Setting up corrected string\n",
    "    result = ''\n",
    "    for token in corrected_tokens:\n",
    "        if token.isalnum() or token in preserve:\n",
    "            if token in preserve:\n",
    "                result += token\n",
    "            else:\n",
    "                result += ' ' + token\n",
    "    return result.strip()\n",
    "\n",
    "data['review'] = data['review'].apply(spell_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6: Converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7: Train-Test split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 8: Saving preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('../data/train_data.csv', index = False)\n",
    "\n",
    "test_data.to_csv('../data/test_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
