{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import contractions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, AutoConfig\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load final test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = pd.read_csv('../data/check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing final test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encoding the labels\n",
    "\n",
    "final_test_data['sentiment'] = final_test_data['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "\n",
    "# Removing HTML line-breaks + links\n",
    "\n",
    "def remove_html_links(review_text):\n",
    "    # Remove HTML line breaks <br />\n",
    "    text = re.sub(r'<.*?>', ' ', review_text)\n",
    "    # Remove http(s) links\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    # Remove dots between capital letters\n",
    "    text = re.sub(r'(?<=\\b[A-Z])\\.(?=[A-Z]\\b)', '', text)\n",
    "    # Remove parentheses with only numbers inside\n",
    "    text = re.sub(r'\\(\\d+\\)', '', text)\n",
    "    # Remove parentheses with content where all words are capitalized\n",
    "    text = re.sub(r'\\(([A-Z][a-z]*(?: [A-Z][a-z]*)*)\\)', '', text)\n",
    "    # Remove all dots between letters and '!' or '?'\n",
    "    text = re.sub(r'(?<=[a-zA-Z])\\.+(?=[!?])', '', text)\n",
    "    # Replace multiple '!', '?' or '-' with just one of each in sequence\n",
    "    text = re.sub(r'[!?-]+', lambda x: ''.join(sorted(set(x.group(0)), key = x.group(0).find)), text)\n",
    "    # Replace sequences of more than two identical letters with exactly two\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    # Replace '@' between letters with a space\n",
    "    text = re.sub(r'(?<=[a-zA-Z])@(?!\\s)', 'a', text)\n",
    "    # Replace '\\', '/' and '>' with a space\n",
    "    text = re.sub(r'[\\\\/>]', ' ', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Replace ' & ' with 'and'\n",
    "    cleaned_text = re.sub(r' \\& ', ' and ', text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "final_test_data['review'] = final_test_data['review'].apply(remove_html_links)\n",
    "\n",
    "\n",
    "# Handling contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "final_test_data['review'] = final_test_data['review'].apply(expand_contractions)\n",
    "\n",
    "\n",
    "# Applying spell check\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance = 2, prefix_length = 7)\n",
    "\n",
    "sym_spell.load_dictionary('../data/frequency_dictionary_en_82_765.txt', term_index = 0, count_index = 1)\n",
    "\n",
    "preserve = {'.', '?', '!', ',', '-', ':', ';', '(', ')'}\n",
    "\n",
    "skip_chars = {'I'}\n",
    "\n",
    "def spell_check(text):\n",
    "    # Splitting text into words and punctuation marks\n",
    "    tokens = re.findall(r'\\w+|\\S', text)\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalnum() and token not in preserve and token not in skip_chars:\n",
    "            suggestions = sym_spell.lookup(token, Verbosity.CLOSEST, max_edit_distance = 2)\n",
    "            corrected_token = suggestions[0].term if suggestions else token\n",
    "            corrected_tokens.append(corrected_token)\n",
    "        else:\n",
    "            corrected_tokens.append(token)\n",
    "    # Setting up corrected string\n",
    "    result = ''\n",
    "    for token in corrected_tokens:\n",
    "        if token.isalnum() or token in preserve:\n",
    "            if token in preserve:\n",
    "                result += token\n",
    "            else:\n",
    "                result += ' ' + token\n",
    "    return result.strip()\n",
    "\n",
    "final_test_data['review'] = final_test_data['review'].apply(spell_check)\n",
    "\n",
    "\n",
    "# Converting to lowercase\n",
    "\n",
    "final_test_data['review'] = final_test_data['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model, tokenizer and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('../models/distilbert/config.json')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('../models/distilbert', config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing final test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = final_test_data['review'].tolist()\n",
    "true_labels = final_test_data['sentiment'].tolist()\n",
    "\n",
    "inputs = tokenizer(reviews, padding = True, truncation = True, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "chunk_size = 100\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for start in range(0, len(inputs['input_ids']), chunk_size):\n",
    "    end = min(start + chunk_size, len(inputs['input_ids']))\n",
    "    chunk_dataset = TensorDataset(inputs['input_ids'][start:end], inputs['attention_mask'][start:end])\n",
    "    chunk_dataloader = DataLoader(chunk_dataset, batch_size = batch_size, num_workers = 0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in chunk_dataloader:\n",
    "            batch_input_ids, batch_attention_mask = batch\n",
    "            batch_inputs = {\n",
    "                'input_ids': batch_input_ids.to('cpu'),\n",
    "                'attention_mask': batch_attention_mask.to('cpu')\n",
    "            }\n",
    "            outputs = model(**batch_inputs)\n",
    "            logits = outputs.logits\n",
    "            batch_predictions = torch.argmax(logits, dim = 1).cpu().numpy()\n",
    "            predictions.extend(batch_predictions)\n",
    "\n",
    "            del batch_inputs, outputs\n",
    "            gc.collect()\n",
    "\n",
    "with open('../models/predictions.txt', 'w') as f:\n",
    "    for item in predictions:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/predictions.txt', 'r') as file:\n",
    "    predictions = [int(line) for line in file]\n",
    "\n",
    "print('Truth:', true_labels[:25])\n",
    "print('Preds:', predictions[:25],'\\n')\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy on the new test set: {accuracy:.2%}\\n\")\n",
    "\n",
    "print(classification_report(true_labels, predictions, target_names = ['negative', 'positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
